{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e31b3fd",
   "metadata": {},
   "source": [
    "1. Introdução\n",
    "Este notebook detalha o processo de análise de dados de acidentes de trânsito em Porto Alegre, a criação de um agente inteligente para recomendação de medidas de moderação de tráfego e a construção de um modelo preditivo para estimar a ocorrência de acidentes futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97b832",
   "metadata": {},
   "source": [
    "1.1. Configuração do Ambiente e Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação e Análise de Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualização de Dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Geocodificação e APIs\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Modelagem Preditiva\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Utilitários\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94198862",
   "metadata": {},
   "source": [
    "2. Coleta, Limpeza e Enriquecimento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a861a",
   "metadata": {},
   "source": [
    "2.1. Carga e Limpeza Inicial do Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "df = pd.read_csv('acidentes.csv', sep=';', low_memory=False)\n",
    "\n",
    "# Limpeza inicial dos nomes das colunas\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Converter colunas de data e hora\n",
    "df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
    "df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S.%f', errors='coerce').dt.time\n",
    "\n",
    "# Combinar data e hora em uma única coluna datetime\n",
    "df['data_hora'] = df.apply(lambda r: pd.datetime.combine(r['data'], r['hora']) if pd.notnull(r['data']) and pd.notnull(r['hora']) else pd.NaT, axis=1)\n",
    "df = df.dropna(subset=['data_hora'])\n",
    "\n",
    "# Tratar coordenadas inválidas (0 ou nulas)\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "df.loc[df['latitude'] == 0, 'latitude'] = np.nan\n",
    "df.loc[df['longitude'] == 0, 'longitude'] = np.nan\n",
    "\n",
    "# Criar colunas agregadas para vítimas e veículos\n",
    "df['total_vitimas'] = df['feridos'] + df['fatais']\n",
    "veiculo_cols = ['auto', 'taxi', 'lotacao', 'onibus_urb', 'onibus_met', 'onibus_int', 'caminhao', 'moto', 'carroca', 'bicicleta', 'outro', 'patinete']\n",
    "df['total_veiculos'] = df[veiculo_cols].sum(axis=1)\n",
    "\n",
    "# Criar coluna de severidade\n",
    "def define_severidade(row):\n",
    "    if row['fatais'] > 0:\n",
    "        return 'Fatal'\n",
    "    elif row['feridos'] > 0:\n",
    "        return 'Com Feridos'\n",
    "    else:\n",
    "        return 'Sem Vítimas'\n",
    "df['severidade'] = df.apply(define_severidade, axis=1)\n",
    "\n",
    "print(f\"Dataset carregado com {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e64b5",
   "metadata": {},
   "source": [
    "2.2. Enriquecimento Geoespacial via Geocodificação\n",
    "Muitos registros não possuem coordenadas de latitude e longitude. Usaremos a API Nominatim (OpenStreetMap) para geocodificar os endereços (logradouros e cruzamentos) e preencher os dados faltantes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
