{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8bfd06",
   "metadata": {},
   "source": [
    "Aqui são apresentados os métodos usados na limpeza, transformação, enriquecimento, as ferramentas que serão utilizadas na análise. Esse capítulo será desenvolvido em três partes: a) construção do dataset principal, com o enriquecimento, conexão com API meteorológica, construção do Jupyter notebook, importação das bibliotecas Pandas, Resquests, Matplot, Seaborn, Plotly Express;  b) tratamento e limpeza, convertendo os tipos, tratando dados ausentes, desenvolvendo engenharia de variáveis (feature engineering); c) análise exploratória dos dados.\n",
    "Serão apresentadas os insights extraídos dessa análisedividida em três vertentes:\n",
    "•\tTemporal: existe uma sazonalidade? Quais dias de semana são mais críticos? Existe um horário com maior índice de acidentes?\n",
    "•\tTipo de acidente: quais são mais comuns? Quais tipos de veículo mais se envolve em acidentes? Quais tipos tem mais vítimas?\n",
    "•\tAnálise de severidade: qual a gravidade? Teve vítima fatal? Quais veículos causam mais vítimas? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a41e1",
   "metadata": {},
   "source": [
    "Importa as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dca2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR BIBLIOTECAS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa706c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Carrega dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a7eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV original lido com sucesso! Primeiras 5 linhas:\n",
      "         data_extracao  predial1  queda_arr                 data  feridos  \\\n",
      "0  2025-06-01 01:33:13       0.0        0.0  2020-10-17 00:00:00        1   \n",
      "1  2025-06-01 01:33:13     598.0        0.0  2020-01-01 00:00:00        1   \n",
      "2  2025-06-01 01:33:13    1271.0        0.0  2020-01-01 00:00:00        1   \n",
      "3  2025-06-01 01:33:13    1901.0        0.0  2020-01-02 00:00:00        2   \n",
      "4  2025-06-01 01:33:13    3302.0        0.0  2020-01-02 00:00:00        1   \n",
      "\n",
      "   feridos_gr  mortes  morte_post  fatais  auto  ...  longitude   latitude  \\\n",
      "0           0       0           0       0     3  ...   0.000000   0.000000   \n",
      "1           0       0           0       0     0  ...        NaN        NaN   \n",
      "2           1       0           0       0     1  ...        NaN        NaN   \n",
      "3           0       0           0       0     0  ...        NaN        NaN   \n",
      "4           0       0           0       0     1  ... -51.211535 -30.081535   \n",
      "\n",
      "                 log1              log2      tipo_acid       dia_sem  \\\n",
      "0    R MARCOS MOREIRA  R GASTON ENGLERT   ABALROAMENTO        SÁBADO   \n",
      "1  AV BENTO GONCALVES               NaN   ABALROAMENTO  QUARTA-FEIRA   \n",
      "2    AV INDEPENDENCIA               NaN  ATROPELAMENTO  QUARTA-FEIRA   \n",
      "3    AV EDUARDO PRADO               NaN  ATROPELAMENTO  QUINTA-FEIRA   \n",
      "4      AV TERESOPOLIS               NaN   ABALROAMENTO  QUINTA-FEIRA   \n",
      "\n",
      "               hora  noite_dia  regiao  consorcio  \n",
      "0  19:00:00.0000000      NOITE   NORTE        NaN  \n",
      "1  03:00:00.0000000      NOITE   LESTE        NaN  \n",
      "2  23:00:00.0000000      NOITE   LESTE        NaN  \n",
      "3  00:05:00.0000000      NOITE     SUL        NaN  \n",
      "4  09:00:00.0000000        DIA     SUL        NaN  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Informações do DataFrame original:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69521 entries, 0 to 69520\n",
      "Data columns (total 34 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   data_extracao  69521 non-null  object \n",
      " 1   predial1       65442 non-null  float64\n",
      " 2   queda_arr      69521 non-null  float64\n",
      " 3   data           69521 non-null  object \n",
      " 4   feridos        69521 non-null  int64  \n",
      " 5   feridos_gr     69521 non-null  int64  \n",
      " 6   mortes         69521 non-null  int64  \n",
      " 7   morte_post     69521 non-null  int64  \n",
      " 8   fatais         69521 non-null  int64  \n",
      " 9   auto           69521 non-null  int64  \n",
      " 10  taxi           69521 non-null  int64  \n",
      " 11  lotacao        69521 non-null  int64  \n",
      " 12  onibus_urb     69521 non-null  int64  \n",
      " 13  onibus_met     69521 non-null  int64  \n",
      " 14  onibus_int     69521 non-null  int64  \n",
      " 15  caminhao       69521 non-null  int64  \n",
      " 16  moto           69521 non-null  int64  \n",
      " 17  carroca        69521 non-null  int64  \n",
      " 18  bicicleta      69521 non-null  int64  \n",
      " 19  outro          69521 non-null  int64  \n",
      " 20  cont_vit       69521 non-null  int64  \n",
      " 21  ups            69521 non-null  int64  \n",
      " 22  patinete       69521 non-null  int64  \n",
      " 23  idacidente     69521 non-null  int64  \n",
      " 24  longitude      59218 non-null  float64\n",
      " 25  latitude       59218 non-null  float64\n",
      " 26  log1           69471 non-null  object \n",
      " 27  log2           19172 non-null  object \n",
      " 28  tipo_acid      69521 non-null  object \n",
      " 29  dia_sem        69521 non-null  object \n",
      " 30  hora           68968 non-null  object \n",
      " 31  noite_dia      69521 non-null  object \n",
      " 32  regiao         69520 non-null  object \n",
      " 33  consorcio      2207 non-null   object \n",
      "dtypes: float64(4), int64(20), object(10)\n",
      "memory usage: 18.0+ MB\n",
      "\n",
      "Arquivo ajustado salvo como 'dados/acidentes-virgula.csv' com separador ','.\n"
     ]
    }
   ],
   "source": [
    "# CARREGAR BANCO DE DADOS\n",
    "# AJUSTAR COLUNAS\n",
    "\n",
    "caminho_dados = 'dados/acidentes.csv'\n",
    "separador_original = ';'\n",
    "codificacao = 'utf-8'\n",
    "\n",
    "caminho_dados_virgula = 'dados/acidentes-virgula.csv'\n",
    "separador_virgula = ','\n",
    "\n",
    "try:\n",
    "    # 1. Carrega o CSV original usando o separador (;)\n",
    "    df = pd.read_csv(caminho_dados, sep=separador_original, encoding=codificacao)\n",
    "\n",
    "    print(\"CSV original lido com sucesso! Primeiras 5 linhas:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nInformações do DataFrame original:\")\n",
    "    df.info()\n",
    "\n",
    "    # 2. Salva o DataFrame em um novo arquivo CSV usando a vírgula (,) como separador\n",
    "    # index=False evita que o Pandas grave o índice do DataFrame como uma nova coluna no CSV\n",
    "    df.to_csv(caminho_dados_virgula, sep=separador_virgula, encoding=codificacao, index=False)\n",
    "\n",
    "    print(f\"\\nArquivo ajustado salvo como '{caminho_dados_virgula}' com separador '{separador_virgula}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo '{caminho_dados}' não encontrado. Verifique o caminho.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "384dc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Nomes de todas as colunas no seu DataFrame: ---\n",
      "['data_extracao', 'predial1', 'queda_arr', 'data', 'feridos', 'feridos_gr', 'mortes', 'morte_post', 'fatais', 'auto', 'taxi', 'lotacao', 'onibus_urb', 'onibus_met', 'onibus_int', 'caminhao', 'moto', 'carroca', 'bicicleta', 'outro', 'cont_vit', 'ups', 'patinete', 'idacidente', 'longitude', 'latitude', 'log1', 'log2', 'tipo_acid', 'dia_sem', 'hora', 'noite_dia', 'regiao', 'consorcio']\n",
      "\n",
      "--- Nomes das colunas após remover espaços em branco: ---\n",
      "['data_extracao', 'predial1', 'queda_arr', 'data', 'feridos', 'feridos_gr', 'mortes', 'morte_post', 'fatais', 'auto', 'taxi', 'lotacao', 'onibus_urb', 'onibus_met', 'onibus_int', 'caminhao', 'moto', 'carroca', 'bicicleta', 'outro', 'cont_vit', 'ups', 'patinete', 'idacidente', 'longitude', 'latitude', 'log1', 'log2', 'tipo_acid', 'dia_sem', 'hora', 'noite_dia', 'regiao', 'consorcio']\n"
     ]
    }
   ],
   "source": [
    "# LIMPA NOMES COLUNAS\n",
    "\n",
    "df = pd.read_csv('dados/acidentes-virgula.csv')\n",
    "\n",
    "print(\"\\n--- Nomes de todas as colunas no seu DataFrame: ---\")\n",
    "print(df.columns.tolist()) # Isso vai te dar a lista exata dos nomes das colunas\n",
    "\n",
    "# Cria variável para armazenar coluna\n",
    "coluna_data = 'data'\n",
    "\n",
    "# Remove espaços em branco no início/fim dos nomes das colunas (boa prática)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Re-imprime para ver se o nome da coluna de data foi limpo\n",
    "print(\"\\n--- Nomes das colunas após remover espaços em branco: ---\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e12c9c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colunas 'data' e 'idacidente' encontradas no DataFrame.\n",
      "Tipo de dado atual da coluna 'data': datetime64[ns]\n",
      "Tipo de dado após a conversão: datetime64[ns]\n",
      "\n",
      "Coluna 'data' convertida para datetime sem NaTs.\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMA TIPO DATA\n",
    "# EXCLUI DATAS INVÁLIDAS\n",
    "\n",
    "coluna_data = 'data'\n",
    "coluna_id = 'idacidente'\n",
    "\n",
    "if coluna_data in df.columns and coluna_id in df.columns:\n",
    "\n",
    "    print(f\"\\nColunas '{coluna_data}' e '{coluna_id}' encontradas no DataFrame.\")\n",
    "\n",
    "    # Converte a Coluna de Data para Datetime\n",
    "    print(f\"Tipo de dado atual da coluna '{coluna_data}': {df[coluna_data].dtype}\")\n",
    "    df[coluna_data] = pd.to_datetime(df[coluna_data], errors='coerce')\n",
    "    print(f\"Tipo de dado após a conversão: {df[coluna_data].dtype}\")\n",
    "\n",
    "    # Identifica e Imprimi ID do Acidente de Datas Inválidas\n",
    "    # Cria um DataFrame contendo apenas as linhas onde a coluna de data é NaT (inválida)\n",
    "    datas_invalidas_df = df[df[coluna_data].isna()]\n",
    "    datas_invalidas_count = len(datas_invalidas_df)\n",
    "\n",
    "    if datas_invalidas_count > 0:\n",
    "        print(f\"\\nATENÇÃO: {datas_invalidas_count} datas inválidas (NaT) foram geradas na coluna '{coluna_data}'.\")\n",
    "        print(f\"IDs de acidente para as datas inválidas:\")\n",
    "        print(f\"DF datas invalidas\\n{datas_invalidas_df}\")\n",
    "        # Itera sobre o DataFrame de datas inválidas e imprime o ID do acidente para cada linha\n",
    "        for idx, row in datas_invalidas_df.iterrows():\n",
    "            print(f\"- ID do Acidente: {row[coluna_id]}\")\n",
    "            # Remove linha com data inválida\n",
    "            primiera_linha = len(df)\n",
    "            df = df.dropna(subset=[coluna_data])\n",
    "            rows_removed = primiera_linha - len(df)\n",
    "        print(f\"\\n{rows_removed} linhas com datas inválidas foram removidas do DataFrame.\")\n",
    "    else:\n",
    "        print(f\"\\nColuna '{coluna_data}' convertida para datetime sem NaTs.\")\n",
    "\n",
    "\n",
    "    df['ano'] = df['data'].dt.year\n",
    "    df['mes'] = df['data'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b41d8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'data_extração' e 'consorcio'\n",
    "\n",
    "colunas_remover = ['data_extracao', 'consorcio']\n",
    "colunas_existentes = [col for col in colunas_remover if col in df.columns]\n",
    "\n",
    "if colunas_existentes:\n",
    "    df = df.drop(columns=colunas_existentes)\n",
    "    print(f\"Colunas extracao e consorcio removidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f18977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame Filtrado por Ano (2020 a 2024) ---\n",
      "Número de linhas no DataFrame original: 69520\n",
      "Número de linhas no DataFrame filtrado: 66120\n",
      "\n",
      ">>> Primeiras 5 linhas do DataFrame Filtrado:\n",
      "   predial1  queda_arr       data  feridos  feridos_gr  mortes  morte_post  \\\n",
      "0       0.0        0.0 2020-10-17        1           0       0           0   \n",
      "1     598.0        0.0 2020-01-01        1           0       0           0   \n",
      "2    1271.0        0.0 2020-01-01        1           1       0           0   \n",
      "3    1901.0        0.0 2020-01-02        2           0       0           0   \n",
      "4    3302.0        0.0 2020-01-02        1           0       0           0   \n",
      "\n",
      "   fatais  auto  taxi  ...                log1              log2  \\\n",
      "0       0     3     0  ...    R MARCOS MOREIRA  R GASTON ENGLERT   \n",
      "1       0     0     1  ...  AV BENTO GONCALVES               NaN   \n",
      "2       0     1     0  ...    AV INDEPENDENCIA               NaN   \n",
      "3       0     0     0  ...    AV EDUARDO PRADO               NaN   \n",
      "4       0     1     0  ...      AV TERESOPOLIS               NaN   \n",
      "\n",
      "       tipo_acid       dia_sem              hora  noite_dia  regiao   ano  \\\n",
      "0   ABALROAMENTO        SÁBADO  19:00:00.0000000      NOITE   NORTE  2020   \n",
      "1   ABALROAMENTO  QUARTA-FEIRA  03:00:00.0000000      NOITE   LESTE  2020   \n",
      "2  ATROPELAMENTO  QUARTA-FEIRA  23:00:00.0000000      NOITE   LESTE  2020   \n",
      "3  ATROPELAMENTO  QUINTA-FEIRA  00:05:00.0000000      NOITE     SUL  2020   \n",
      "4   ABALROAMENTO  QUINTA-FEIRA  09:00:00.0000000        DIA     SUL  2020   \n",
      "\n",
      "   mes  dia  \n",
      "0   10   17  \n",
      "1    1    1  \n",
      "2    1    1  \n",
      "3    1    2  \n",
      "4    1    2  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      ">>> Contagem de registros por ano (filtrado):\n",
      "data\n",
      "2020     9294\n",
      "2021    12398\n",
      "2022    13922\n",
      "2023    15514\n",
      "2024    14992\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filtra o DataFrame por Ano\n",
    "ano_inicio = 2020\n",
    "ano_fim = 2024\n",
    "\n",
    "# A filtragem agora usa o coluna_data\n",
    "df_filtrado = df[\n",
    "    (df[coluna_data].dt.year >= ano_inicio) &\n",
    "    (df[coluna_data].dt.year <= ano_fim)\n",
    "]\n",
    "\n",
    "print(f\"\\n--- DataFrame Filtrado por Ano ({ano_inicio} a {ano_fim}) ---\")\n",
    "print(f\"Número de linhas no DataFrame original: {len(df)}\")\n",
    "print(f\"Número de linhas no DataFrame filtrado: {len(df_filtrado)}\")\n",
    "\n",
    "print(\"\\n>>> Primeiras 5 linhas do DataFrame Filtrado:\")\n",
    "print(df_filtrado.head())\n",
    "print(\"\\n>>> Contagem de registros por ano (filtrado):\")\n",
    "print(df_filtrado[coluna_data].dt.year.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "591c1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Informações Gerais do Dataset Após Limpeza e Conversão ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 66120 entries, 0 to 69344\n",
      "Data columns (total 35 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   predial1    62312 non-null  float64       \n",
      " 1   queda_arr   66120 non-null  float64       \n",
      " 2   data        66120 non-null  datetime64[ns]\n",
      " 3   feridos     66120 non-null  int64         \n",
      " 4   feridos_gr  66120 non-null  int64         \n",
      " 5   mortes      66120 non-null  int64         \n",
      " 6   morte_post  66120 non-null  int64         \n",
      " 7   fatais      66120 non-null  int64         \n",
      " 8   auto        66120 non-null  int64         \n",
      " 9   taxi        66120 non-null  int64         \n",
      " 10  lotacao     66120 non-null  int64         \n",
      " 11  onibus_urb  66120 non-null  int64         \n",
      " 12  onibus_met  66120 non-null  int64         \n",
      " 13  onibus_int  66120 non-null  int64         \n",
      " 14  caminhao    66120 non-null  int64         \n",
      " 15  moto        66120 non-null  int64         \n",
      " 16  carroca     66120 non-null  int64         \n",
      " 17  bicicleta   66120 non-null  int64         \n",
      " 18  outro       66120 non-null  int64         \n",
      " 19  cont_vit    66120 non-null  int64         \n",
      " 20  ups         66120 non-null  int64         \n",
      " 21  patinete    66120 non-null  int64         \n",
      " 22  idacidente  66120 non-null  int64         \n",
      " 23  longitude   56190 non-null  float64       \n",
      " 24  latitude    56190 non-null  float64       \n",
      " 25  log1        66071 non-null  object        \n",
      " 26  log2        18415 non-null  object        \n",
      " 27  tipo_acid   66120 non-null  object        \n",
      " 28  dia_sem     66120 non-null  object        \n",
      " 29  hora        65603 non-null  object        \n",
      " 30  noite_dia   66120 non-null  object        \n",
      " 31  regiao      66119 non-null  object        \n",
      " 32  ano         66120 non-null  int32         \n",
      " 33  mes         66120 non-null  int32         \n",
      " 34  dia         66120 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(4), int32(3), int64(20), object(7)\n",
      "memory usage: 17.4+ MB\n",
      "\n",
      "--- Contagem de Valores Ausentes Após Limpeza e Conversão ---\n",
      "predial1       3808\n",
      "queda_arr         0\n",
      "data              0\n",
      "feridos           0\n",
      "feridos_gr        0\n",
      "mortes            0\n",
      "morte_post        0\n",
      "fatais            0\n",
      "auto              0\n",
      "taxi              0\n",
      "lotacao           0\n",
      "onibus_urb        0\n",
      "onibus_met        0\n",
      "onibus_int        0\n",
      "caminhao          0\n",
      "moto              0\n",
      "carroca           0\n",
      "bicicleta         0\n",
      "outro             0\n",
      "cont_vit          0\n",
      "ups               0\n",
      "patinete          0\n",
      "idacidente        0\n",
      "longitude      9930\n",
      "latitude       9930\n",
      "log1             49\n",
      "log2          47705\n",
      "tipo_acid         0\n",
      "dia_sem           0\n",
      "hora            517\n",
      "noite_dia         0\n",
      "regiao            1\n",
      "ano               0\n",
      "mes               0\n",
      "dia               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Informações Gerais do Dataset Após Limpeza e Conversão ---\")\n",
    "df_filtrado.info()\n",
    "print(\"\\n--- Contagem de Valores Ausentes Após Limpeza e Conversão ---\")\n",
    "print(df_filtrado.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRATA 'LONGITUDE' E 'LATITUDE'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
