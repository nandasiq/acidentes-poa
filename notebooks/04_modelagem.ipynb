{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2caf0e6",
   "metadata": {},
   "source": [
    "# 04 - Modelagem Preditiva\n",
    "Autora: Fernanda Baptista de Siqueira  \n",
    "Curso: MBA em Tecnologia para Negócios – AI, Data Science e Big Data  \n",
    "Tema: Análise de Acidentes de Trânsito em Porto Alegre (2020–2024)  \n",
    "Origem DataFrame: Equipe Armazém de Dados de Mobilidade - EAMOB/CIET  \n",
    "https://dadosabertos.poa.br/dataset/acidentes-de-transito-acidentes (11/05/2025)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3a2b2",
   "metadata": {},
   "source": [
    "### 1. Importa bibliotecas e funções. Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cd15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (\n",
    "    pd, sns, plt, np,\n",
    "    resumo_df, ajustar_tipos, \n",
    "    PATH_CLEAN, COLS_VEICULOS,\n",
    "    COLS_CAT, COLS_INT, COLS_STR\n",
    ")\n",
    "\n",
    "# Pré-processamento e modelagem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a256c7d",
   "metadata": {},
   "source": [
    "### 2. Carrega Dados Tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb809e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (68837, 35)\n",
      "\n",
      "Tipos de dados:\n",
      "predial1                   Int32\n",
      "queda_arr                  Int32\n",
      "data              datetime64[ns]\n",
      "feridos                    Int32\n",
      "feridos_gr                 Int32\n",
      "fatais                     Int32\n",
      "auto                       Int32\n",
      "taxi                       Int32\n",
      "lotacao                    Int32\n",
      "onibus_urb                 Int32\n",
      "onibus_met                 Int32\n",
      "onibus_int                 Int32\n",
      "caminhao                   Int32\n",
      "moto                       Int32\n",
      "carroca                    Int32\n",
      "bicicleta                  Int32\n",
      "outro                      Int32\n",
      "cont_vit                   Int32\n",
      "ups                        Int32\n",
      "patinete                   Int32\n",
      "idacidente                 Int32\n",
      "log1              string[python]\n",
      "log2              string[python]\n",
      "tipo_acid               category\n",
      "dia_sem                 category\n",
      "hora             timedelta64[ns]\n",
      "noite_dia               category\n",
      "regiao                  category\n",
      "hora_int                   int64\n",
      "data_hora         datetime64[ns]\n",
      "total_vitimas              Int32\n",
      "soma_veiculos              Int32\n",
      "data_meteo        datetime64[ns]\n",
      "chuva                    float32\n",
      "chovendo                   int64\n",
      "dtype: object\n",
      "\n",
      "Nulos por coluna:\n",
      "predial1          4038\n",
      "queda_arr            0\n",
      "data                 0\n",
      "feridos              0\n",
      "feridos_gr           0\n",
      "fatais               0\n",
      "auto                 0\n",
      "taxi                 0\n",
      "lotacao              0\n",
      "onibus_urb           0\n",
      "onibus_met           0\n",
      "onibus_int           0\n",
      "caminhao             0\n",
      "moto                 0\n",
      "carroca              0\n",
      "bicicleta            0\n",
      "outro                0\n",
      "cont_vit             0\n",
      "ups                  0\n",
      "patinete             0\n",
      "idacidente           0\n",
      "log1                 0\n",
      "log2             49862\n",
      "tipo_acid            0\n",
      "dia_sem              0\n",
      "hora                 0\n",
      "noite_dia            0\n",
      "regiao               0\n",
      "hora_int             0\n",
      "data_hora            0\n",
      "total_vitimas        0\n",
      "soma_veiculos        0\n",
      "data_meteo           0\n",
      "chuva                0\n",
      "chovendo             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predial1</th>\n",
       "      <th>queda_arr</th>\n",
       "      <th>data</th>\n",
       "      <th>feridos</th>\n",
       "      <th>feridos_gr</th>\n",
       "      <th>fatais</th>\n",
       "      <th>auto</th>\n",
       "      <th>taxi</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>onibus_urb</th>\n",
       "      <th>onibus_met</th>\n",
       "      <th>onibus_int</th>\n",
       "      <th>caminhao</th>\n",
       "      <th>moto</th>\n",
       "      <th>carroca</th>\n",
       "      <th>bicicleta</th>\n",
       "      <th>outro</th>\n",
       "      <th>cont_vit</th>\n",
       "      <th>ups</th>\n",
       "      <th>patinete</th>\n",
       "      <th>idacidente</th>\n",
       "      <th>log1</th>\n",
       "      <th>log2</th>\n",
       "      <th>tipo_acid</th>\n",
       "      <th>dia_sem</th>\n",
       "      <th>hora</th>\n",
       "      <th>noite_dia</th>\n",
       "      <th>regiao</th>\n",
       "      <th>hora_int</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>total_vitimas</th>\n",
       "      <th>soma_veiculos</th>\n",
       "      <th>data_meteo</th>\n",
       "      <th>chuva</th>\n",
       "      <th>chovendo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669196</td>\n",
       "      <td>AV FARRAPOS</td>\n",
       "      <td>AV SAO PEDRO</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 02:20:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>669089</td>\n",
       "      <td>AV BENTO GONCALVES</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669206</td>\n",
       "      <td>R SANTA FLORA</td>\n",
       "      <td>AV DA CAVALHADA</td>\n",
       "      <td>COLISÃO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>SUL</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669195</td>\n",
       "      <td>R SAO FRANCISCO DE ASSIS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EVENTUAL</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>683303</td>\n",
       "      <td>AV SENADOR TARSO DUTRA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>23</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predial1  queda_arr       data  feridos  feridos_gr  fatais  auto  taxi  \\\n",
       "0      2500          0 2020-01-01        0           0       0     2     0   \n",
       "1       598          0 2020-01-01        1           0       0     0     1   \n",
       "2         0          0 2020-01-01        0           0       0     2     0   \n",
       "3       399          0 2020-01-01        0           0       0     1     0   \n",
       "4       400          0 2020-01-01        1           1       0     0     0   \n",
       "\n",
       "   lotacao  onibus_urb  onibus_met  onibus_int  caminhao  moto  carroca  \\\n",
       "0        0           0           0           0         0     0        0   \n",
       "1        0           0           0           0         0     1        0   \n",
       "2        0           0           0           0         0     0        0   \n",
       "3        0           0           0           0         0     0        0   \n",
       "4        0           0           0           0         0     1        0   \n",
       "\n",
       "   bicicleta  outro  cont_vit  ups  patinete  idacidente  \\\n",
       "0          0      0         0    1         0      669196   \n",
       "1          0      0         1    5         0      669089   \n",
       "2          0      0         0    1         0      669206   \n",
       "3          0      0         0    1         0      669195   \n",
       "4          1      0         1    5         0      683303   \n",
       "\n",
       "                       log1             log2     tipo_acid dia_sem  \\\n",
       "0               AV FARRAPOS     AV SAO PEDRO  ABALROAMENTO  Quarta   \n",
       "1        AV BENTO GONCALVES             <NA>  ABALROAMENTO  Quarta   \n",
       "2             R SANTA FLORA  AV DA CAVALHADA       COLISÃO  Quarta   \n",
       "3  R SAO FRANCISCO DE ASSIS             <NA>      EVENTUAL  Quarta   \n",
       "4   AV SENADOR TARSO DUTRA              <NA>  ABALROAMENTO  Quarta   \n",
       "\n",
       "             hora noite_dia regiao  hora_int           data_hora  \\\n",
       "0 0 days 02:20:00     NOITE  NORTE         2 2020-01-01 02:20:00   \n",
       "1 0 days 03:00:00     NOITE  LESTE         3 2020-01-01 03:00:00   \n",
       "2 0 days 17:15:00       DIA    SUL        17 2020-01-01 17:15:00   \n",
       "3 0 days 17:15:00       DIA  NORTE        17 2020-01-01 17:15:00   \n",
       "4 0 days 23:00:00     NOITE  LESTE        23 2020-01-01 23:00:00   \n",
       "\n",
       "   total_vitimas  soma_veiculos          data_meteo  chuva  chovendo  \n",
       "0              0              2 2020-01-01 02:00:00   0.00         0  \n",
       "1              1              2 2020-01-01 03:00:00   0.00         0  \n",
       "2              0              2 2020-01-01 17:00:00   0.40         1  \n",
       "3              0              1 2020-01-01 17:00:00   5.70         1  \n",
       "4              1              2 2020-01-01 23:00:00   0.00         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((68837, 35), (68837, 34), (68837,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega dataset já limpo\n",
    "df = pd.read_parquet(PATH_CLEAN + 'df_limpo_chuva.parquet')\n",
    "resumo_df(df)\n",
    "\n",
    "# Define target (UPS = severidade)\n",
    "y = df[\"ups\"]\n",
    "X = df.drop(columns=[\"ups\"])\n",
    "\n",
    "df.shape, X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fe1ad",
   "metadata": {},
   "source": [
    "### 3. Separa Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fabd3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48185, 34), (10326, 34), (10326, 34))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70% treino, 15% validação, 15% teste\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "# Converte todos os pd.NA -> np.nan\n",
    "for df_part in [X_train, X_valid, X_test]:\n",
    "    df_part.replace({pd.NA: np.nan}, inplace=True)\n",
    "\n",
    "# Converte colunas Int32 (nullable) para float64\n",
    "for df_part in [X_train, X_valid, X_test]:\n",
    "    int_cols = df_part.select_dtypes(include=\"Int32\").columns\n",
    "    if len(int_cols) > 0:\n",
    "        df_part[int_cols] = df_part[int_cols].astype(\"float64\")\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c2060",
   "metadata": {},
   "source": [
    "### 4. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b99797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['log1', 'log2', 'tipo_acid', 'dia_sem', 'noite_dia', 'regiao'],\n",
       " ['auto',\n",
       "  'bicicleta',\n",
       "  'caminhao',\n",
       "  'carroca',\n",
       "  'chovendo',\n",
       "  'chuva',\n",
       "  'cont_vit',\n",
       "  'fatais',\n",
       "  'feridos',\n",
       "  'feridos_gr',\n",
       "  'hora_int',\n",
       "  'idacidente',\n",
       "  'lotacao',\n",
       "  'moto',\n",
       "  'onibus_int',\n",
       "  'onibus_met',\n",
       "  'onibus_urb',\n",
       "  'outro',\n",
       "  'patinete',\n",
       "  'predial1',\n",
       "  'queda_arr',\n",
       "  'soma_veiculos',\n",
       "  'taxi',\n",
       "  'total_vitimas'],\n",
       " ['data', 'data_hora', 'data_meteo'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Categóricas: inclui object, category e string[python]\n",
    "cat_cols = (\n",
    "    X_train.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns.tolist()\n",
    ")\n",
    "\n",
    "# Datas\n",
    "date_cols = X_train.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns.tolist()\n",
    "\n",
    "num_cols = X_train.select_dtypes(\n",
    "    include=[\"float32\", \"float64\", \"int32\", \"int64\", \"Int32\", \"Float32\"]\n",
    ").columns.difference(cat_cols + date_cols).tolist()\n",
    "\n",
    "# Numéricas: vamos confiar na lista fixa (COLS_INT) + floats detectados\n",
    "#num_cols = [c for c in COLS_INT if c in X_train.columns]\n",
    "#num_cols += X_train.select_dtypes(include=[\"float32\", \"float64\", \"int32\", \"int64\"]).columns.difference(cat_cols + date_cols).tolist()\n",
    "\n",
    "cat_cols, num_cols, date_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7bb603",
   "metadata": {},
   "source": [
    "### 5. Pré-processadores (linear vs árvores)\n",
    "* Linear (Ridge) usa One-Hot (bom para linearidade)\n",
    "* Árvores (RF/GB) usam Ordinal (rápido e não explode colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017bb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines básicos\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "def make_date_features(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X_df = X_df.copy()\n",
    "    out = pd.DataFrame(index=X_df.index)\n",
    "    for c in X_df.columns:\n",
    "        s = X_df[c]\n",
    "        # se vier timezone-aware, normaliza para naive\n",
    "        try:\n",
    "            if hasattr(s.dt, \"tz\") and s.dt.tz is not None:\n",
    "                s = s.dt.tz_convert(\"America/Sao_Paulo\").dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            # se não for datetime, retorna vazio (não deveria ocorrer aqui)\n",
    "            return pd.DataFrame(index=X_df.index)\n",
    "        out[f\"{c}__year\"]  = s.dt.year\n",
    "        out[f\"{c}__month\"] = s.dt.month\n",
    "        out[f\"{c}__dow\"]   = s.dt.dayofweek\n",
    "        out[f\"{c}__hour\"]  = s.dt.hour\n",
    "    return out\n",
    "\n",
    "datetime_pipe = Pipeline([\n",
    "    (\"extract\", FunctionTransformer(make_date_features, validate=False)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categóricas:\n",
    "# -> OHE sem 'sparse'/'sparse_output' para ser compatível com 1.1/1.2/1.4+\n",
    "categorical_ohe_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Árvores: OrdinalEncoder (simples e rápido). 'encoded_missing_value' removido para compatibilidade ampla\n",
    "categorical_ord_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ord\", OrdinalEncoder(\n",
    "        handle_unknown=\"use_encoded_value\",\n",
    "        unknown_value=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# Pré-processador para modelos lineares (OHE)\n",
    "preprocess_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\",  numeric_pipe,   num_cols),\n",
    "        (\"date\", datetime_pipe,  date_cols),\n",
    "        (\"cat\",  categorical_ohe_pipe, cat_cols),\n",
    "    ],\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "# Pré-processador para árvores (Ordinal)\n",
    "preprocess_trees = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\",  numeric_pipe,   num_cols),\n",
    "        (\"date\", datetime_pipe,  date_cols),\n",
    "        (\"cat\",  categorical_ord_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e582bb",
   "metadata": {},
   "source": [
    "### 6. Modelos Candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f55b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de modelos\n",
    "modelos = {\n",
    "    \"Ridge (linear)\": Pipeline([\n",
    "        (\"prep\", preprocess_linear),\n",
    "        (\"model\", Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"prep\", preprocess_trees),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    \"GradientBoosting\": Pipeline([\n",
    "        (\"prep\", preprocess_trees),\n",
    "        (\"model\", GradientBoostingRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb20833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numéricas detectadas: ['auto', 'bicicleta', 'caminhao', 'carroca', 'chovendo', 'chuva', 'cont_vit', 'fatais', 'feridos', 'feridos_gr', 'hora_int', 'idacidente', 'lotacao', 'moto', 'onibus_int', 'onibus_met', 'onibus_urb', 'outro', 'patinete', 'predial1', 'queda_arr', 'soma_veiculos', 'taxi', 'total_vitimas']\n",
      "Categóricas detectadas: ['log1', 'log2', 'tipo_acid', 'dia_sem', 'noite_dia', 'regiao']\n",
      "Datas detectadas: ['data', 'data_hora', 'data_meteo']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numéricas detectadas:\", num_cols)\n",
    "print(\"Categóricas detectadas:\", cat_cols)\n",
    "print(\"Datas detectadas:\", date_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbb4de",
   "metadata": {},
   "source": [
    "### 7. Treino e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2b5de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "boolean value of NA is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m resultados = {}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nome, pipe \u001b[38;5;129;01min\u001b[39;00m modelos.items():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     y_pred = pipe.predict(X_valid)\n\u001b[32m      7\u001b[39m     rmse = mean_squared_error(y_valid, y_pred, squared=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:996\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    994\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:897\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    885\u001b[39m             extra_args = {}\n\u001b[32m    886\u001b[39m         jobs.append(\n\u001b[32m    887\u001b[39m             delayed(func)(\n\u001b[32m    888\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m             )\n\u001b[32m    895\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:719\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m    682\u001b[39m \u001b[33;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m \u001b[33;03m    Transformed samples.\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    718\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m last_step = \u001b[38;5;28mself\u001b[39m._final_estimator\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:897\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:469\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28mself\u001b[39m.statistics_ = \u001b[38;5;28mself\u001b[39m._sparse_fit(\n\u001b[32m    466\u001b[39m         X, \u001b[38;5;28mself\u001b[39m.strategy, \u001b[38;5;28mself\u001b[39m.missing_values, fill_value\n\u001b[32m    467\u001b[39m     )\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     \u001b[38;5;28mself\u001b[39m.statistics_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dense_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:535\u001b[39m, in \u001b[36mSimpleImputer._dense_fit\u001b[39m\u001b[34m(self, X, strategy, missing_values, fill_value)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_dense_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, strategy, missing_values, fill_value):\n\u001b[32m    534\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the transformer on dense data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     missing_mask = \u001b[43m_get_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     masked_X = ma.masked_array(X, mask=missing_mask)\n\u001b[32m    538\u001b[39m     \u001b[38;5;28msuper\u001b[39m()._fit_indicator(missing_mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_mask.py:58\u001b[39m, in \u001b[36m_get_mask\u001b[39m\u001b[34m(X, value_to_mask)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the boolean mask X == value_to_mask.\u001b[39;00m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m \u001b[33;03m    Missing mask.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# For all cases apart of a sparse input where we need to reconstruct\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# a sparse output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_dense_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_to_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m Xt = _get_dense_mask(X.data, value_to_mask)\n\u001b[32m     62\u001b[39m sparse_constructor = sp.csr_matrix \u001b[38;5;28;01mif\u001b[39;00m X.format == \u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sp.csc_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_mask.py:31\u001b[39m, in \u001b[36m_get_dense_mask\u001b[39m\u001b[34m(X, value_to_mask)\u001b[39m\n\u001b[32m     28\u001b[39m         Xt = np.zeros(X.shape, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m         \u001b[38;5;66;03m# np.isnan does not work on object dtypes.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         Xt = \u001b[43m_object_dtype_isnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     33\u001b[39m     Xt = X == value_to_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:55\u001b[39m, in \u001b[36m_object_dtype_isnan\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_object_dtype_isnan\u001b[39m(X):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/missing.pyx:392\u001b[39m, in \u001b[36mpandas._libs.missing.NAType.__bool__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: boolean value of NA is ambiguous"
     ]
    }
   ],
   "source": [
    "# Avalia todos os modelos no conjunto de validação\n",
    "resultados = {}\n",
    "\n",
    "for nome, pipe in modelos.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    resultados[nome] = {\"RMSE\": rmse, \"R²\": r2}\n",
    "\n",
    "# Mostra tabela ordenada pelo RMSE\n",
    "pd.DataFrame(resultados).T.sort_values(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa720ac5",
   "metadata": {},
   "source": [
    "Escolher menor RMSE ou MAE e maior r² na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b605e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_nome = ranking.index[0]\n",
    "best_pipe = resultados[melhor_nome][\"pipeline\"]\n",
    "print(\"🏆 Melhor modelo (val):\", melhor_nome, resultados[melhor_nome][\"val\"])\n",
    "\n",
    "# Avaliar no teste (se existir)\n",
    "if not X_test.empty:\n",
    "    yhat_test = best_pipe.predict(X_test)\n",
    "    print(\"Teste:\", avaliar(y_test, yhat_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c83c1f",
   "metadata": {},
   "source": [
    "7) Importância de features & interpretabilidade\n",
    "\n",
    "Para árvores, usamos feature_importances_. Para modelos lineares, coeficientes.\n",
    "Se você tiver SHAP instalado, incluí um bloco opcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be243560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomes_features_transformados(preprocessor):\n",
    "    # Recupera nomes após OneHotEncoder\n",
    "    out = []\n",
    "    # num\n",
    "    out += num_cols\n",
    "    # cat\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "    cat_feat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    out += cat_feat_names\n",
    "    return out\n",
    "\n",
    "# Importância (quando aplicável)\n",
    "try:\n",
    "    model = best_pipe.named_steps[\"model\"]\n",
    "    feat_names = nomes_features_transformados(best_pipe.named_steps[\"prep\"])\n",
    "\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = pd.Series(model.feature_importances_, index=feat_names).sort_values(ascending=False).head(20)\n",
    "        ax = imp[::-1].plot(kind=\"barh\")\n",
    "        ax.set_title(f\"Top 20 importâncias — {melhor_nome}\")\n",
    "        plt.show()\n",
    "\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        coefs = pd.Series(model.coef_.ravel(), index=feat_names).sort_values()\n",
    "        ax = coefs.head(10).plot(kind=\"barh\"); plt.title(f\"Coef. (neg) — {melhor_nome}\"); plt.show()\n",
    "        ax = coefs.tail(10).plot(kind=\"barh\"); plt.title(f\"Coef. (pos) — {melhor_nome}\"); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Importância/coeficientes não disponíveis:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20852a",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) é uma ferramenta poderosa para interpretar modelos de machine learning, especialmente modelos complexos como árvores de decisão e redes neurais. Ele atribui a cada feature uma contribuição para a previsão do modelo, permitindo entender como cada variável influencia o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP and hasattr(best_pipe.named_steps[\"model\"], \"predict\"):\n",
    "    # Amostra para reduzir custo\n",
    "    amostra = X_val.sample(min(3000, len(X_val)), random_state=42)\n",
    "    X_val_trans = best_pipe.named_steps[\"prep\"].transform(amostra)\n",
    "\n",
    "    # Escolha do explainer depende do modelo\n",
    "    try:\n",
    "        explainer = shap.Explainer(best_pipe.named_steps[\"model\"])\n",
    "        shap_values = explainer(X_val_trans)\n",
    "        shap.plots.beeswarm(shap_values, max_display=20)\n",
    "    except Exception as e:\n",
    "        print(\"SHAP não pôde rodar com este modelo:\", e)\n",
    "else:\n",
    "    print(\"SHAP indisponível (biblioteca ausente) — pulando.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cadd02",
   "metadata": {},
   "source": [
    "8) Previsão temporal (mensal) com SARIMAX (opcional)\n",
    "\n",
    "Previsão do total mensal de UPS para avaliar tendência de severidade.\n",
    "Ajuste simples; melhore com covariáveis exógenas (chuva média mensal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_STATSMODELS:\n",
    "    # Série mensal de UPS\n",
    "    s_mensal = (df\n",
    "                .dropna(subset=[\"data\"])\n",
    "                .set_index(\"data\")\n",
    "                .resample(\"M\")[\"ups\"].sum())\n",
    "\n",
    "    # Treino até 2023, valida 2024, teste 2025-05\n",
    "    s_train = s_mensal.loc[: \"2023-12-31\"]\n",
    "    s_val   = s_mensal.loc[\"2024-01-01\":\"2024-12-31\"]\n",
    "    s_test  = s_mensal.loc[\"2025-01-01\":\"2025-05-31\"]\n",
    "\n",
    "    # Exógenas (chuva média mensal), se existir\n",
    "    if \"chuva\" in df.columns:\n",
    "        exo = df.set_index(\"data\").resample(\"M\")[\"chuva\"].mean()\n",
    "        exo_train = exo.loc[s_train.index]\n",
    "        exo_val   = exo.loc[s_val.index]\n",
    "        exo_test  = exo.loc[s_test.index] if not s_test.empty else None\n",
    "    else:\n",
    "        exo_train = exo_val = exo_test = None\n",
    "\n",
    "    # Modelo SARIMAX simples\n",
    "    mod = sm.tsa.statespace.SARIMAX(\n",
    "        s_train, order=(1,1,1), seasonal_order=(1,1,1,12),\n",
    "        exog=exo_train, enforce_stationarity=False, enforce_invertibility=False\n",
    "    )\n",
    "    res = mod.fit(disp=False)\n",
    "\n",
    "    pred_val = res.get_forecast(steps=len(s_val), exog=exo_val)\n",
    "    pred_mean_val = pred_val.predicted_mean\n",
    "    ci_val = pred_val.conf_int()\n",
    "\n",
    "    ax = s_mensal.plot(label=\"observado\", alpha=0.6)\n",
    "    pred_mean_val.plot(ax=ax, label=\"previsto (val)\")\n",
    "    ax.fill_between(ci_val.index, ci_val.iloc[:,0], ci_val.iloc[:,1], alpha=0.2)\n",
    "    ax.axvspan(pd.Timestamp(\"2024-01-01\"), pd.Timestamp(\"2024-12-31\"), color=\"orange\", alpha=0.1, label=\"val\")\n",
    "    if not s_test.empty:\n",
    "        ax.axvspan(pd.Timestamp(\"2025-01-01\"), pd.Timestamp(\"2025-05-31\"), color=\"green\", alpha=0.1, label=\"teste\")\n",
    "    ax.set_title(\"UPS mensal — observado vs previsão (SARIMAX)\")\n",
    "    ax.legend(); plt.show()\n",
    "\n",
    "    # Erros em validação\n",
    "    from math import sqrt\n",
    "    rmse_val = sqrt(((s_val - pred_mean_val)**2).mean())\n",
    "    mae_val = (s_val - pred_mean_val).abs().mean()\n",
    "    print({\"RMSE_val_mensal\": rmse_val, \"MAE_val_mensal\": mae_val})\n",
    "else:\n",
    "    print(\"statsmodels indisponível — pulando SARIMAX.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3acadd",
   "metadata": {},
   "source": [
    "9) Conclusões e próximos passos (guia)\n",
    "\n",
    "Desempenho: compare MAE/RMSE/R² entre os modelos; escolha o melhor (geralmente HistGBR e RF vão bem).\n",
    "\n",
    "Interpretabilidade: use importâncias e (se possível) SHAP para entender sinais/efeitos.\n",
    "\n",
    "Aprimoramentos:\n",
    "\n",
    "Features: harmônicos de hora (seno/cosseno), sazonalidade (mês), feriados, interação chuva×noite_dia.\n",
    "\n",
    "Espaço: agrupar log1 para reduzir cardinalidade (top-k + “outros”).\n",
    "\n",
    "Validação: CV em blocos temporais (TimeSeriesSplit) além do hold-out por ano.\n",
    "\n",
    "Incerteza: intervalos por quantile regression (HistGBR loss=\"quantile\") para cenários pessimista/otimista.\n",
    "\n",
    "Temporais: enriquecer SARIMAX com exógenas (chuva, feriados, mobilidade) e comparar com Prophet ou AutoARIMA (pmdarima)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942a8b8",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f561ae8",
   "metadata": {},
   "source": [
    "## Referenciais Teóricos\n",
    "\n",
    "- Breiman (2001): *Two Cultures* → interpretação vs predição.\n",
    "- Bishop (2006), Hastie, Tibshirani & Friedman (2009), Murphy (2012): fundamentos estatísticos e probabilísticos.\n",
    "- Géron (2023), Müller & Guido (2016), Faceli et al. (2021): boas práticas em pipelines e scikit-learn.\n",
    "- Zabala (2019, 2021): aplicações de modelagem preditiva.\n",
    "- Pearl et al. (2016): inferência causal.\n",
    "- Vilone & Longo (2020): interpretabilidade.\n",
    "- Bao et al. (2020): incerteza espaço-temporal.\n",
    "- Chen et al. (2025): ensembles avançados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
