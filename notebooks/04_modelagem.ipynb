{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2caf0e6",
   "metadata": {},
   "source": [
    "# 04 - Modelagem Preditiva\n",
    "Autora: Fernanda Baptista de Siqueira  \n",
    "Curso: MBA em Tecnologia para Negócios – AI, Data Science e Big Data  \n",
    "Tema: Análise de Acidentes de Trânsito em Porto Alegre (2020–2024)  \n",
    "Origem DataFrame: Equipe Armazém de Dados de Mobilidade - EAMOB/CIET  \n",
    "https://dadosabertos.poa.br/dataset/acidentes-de-transito-acidentes (11/05/2025)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3a2b2",
   "metadata": {},
   "source": [
    "### 1. Importa bibliotecas e funções. Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cd15eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (68837, 35)\n",
      "\n",
      "Tipos de dados:\n",
      "predial1                   Int32\n",
      "queda_arr                  Int32\n",
      "data              datetime64[ns]\n",
      "feridos                    Int32\n",
      "feridos_gr                 Int32\n",
      "fatais                     Int32\n",
      "auto                       Int32\n",
      "taxi                       Int32\n",
      "lotacao                    Int32\n",
      "onibus_urb                 Int32\n",
      "onibus_met                 Int32\n",
      "onibus_int                 Int32\n",
      "caminhao                   Int32\n",
      "moto                       Int32\n",
      "carroca                    Int32\n",
      "bicicleta                  Int32\n",
      "outro                      Int32\n",
      "cont_vit                   Int32\n",
      "ups                        Int32\n",
      "patinete                   Int32\n",
      "idacidente                 Int32\n",
      "log1              string[python]\n",
      "log2              string[python]\n",
      "tipo_acid               category\n",
      "dia_sem                 category\n",
      "hora             timedelta64[ns]\n",
      "noite_dia               category\n",
      "regiao                  category\n",
      "hora_int                   int64\n",
      "data_hora         datetime64[ns]\n",
      "total_vitimas              Int32\n",
      "soma_veiculos              Int32\n",
      "data_meteo        datetime64[ns]\n",
      "chuva                    float32\n",
      "chovendo                   int64\n",
      "dtype: object\n",
      "\n",
      "Nulos por coluna:\n",
      "predial1          4038\n",
      "queda_arr            0\n",
      "data                 0\n",
      "feridos              0\n",
      "feridos_gr           0\n",
      "fatais               0\n",
      "auto                 0\n",
      "taxi                 0\n",
      "lotacao              0\n",
      "onibus_urb           0\n",
      "onibus_met           0\n",
      "onibus_int           0\n",
      "caminhao             0\n",
      "moto                 0\n",
      "carroca              0\n",
      "bicicleta            0\n",
      "outro                0\n",
      "cont_vit             0\n",
      "ups                  0\n",
      "patinete             0\n",
      "idacidente           0\n",
      "log1                 0\n",
      "log2             49862\n",
      "tipo_acid            0\n",
      "dia_sem              0\n",
      "hora                 0\n",
      "noite_dia            0\n",
      "regiao               0\n",
      "hora_int             0\n",
      "data_hora            0\n",
      "total_vitimas        0\n",
      "soma_veiculos        0\n",
      "data_meteo           0\n",
      "chuva                0\n",
      "chovendo             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predial1</th>\n",
       "      <th>queda_arr</th>\n",
       "      <th>data</th>\n",
       "      <th>feridos</th>\n",
       "      <th>feridos_gr</th>\n",
       "      <th>fatais</th>\n",
       "      <th>auto</th>\n",
       "      <th>taxi</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>onibus_urb</th>\n",
       "      <th>onibus_met</th>\n",
       "      <th>onibus_int</th>\n",
       "      <th>caminhao</th>\n",
       "      <th>moto</th>\n",
       "      <th>carroca</th>\n",
       "      <th>bicicleta</th>\n",
       "      <th>outro</th>\n",
       "      <th>cont_vit</th>\n",
       "      <th>ups</th>\n",
       "      <th>patinete</th>\n",
       "      <th>idacidente</th>\n",
       "      <th>log1</th>\n",
       "      <th>log2</th>\n",
       "      <th>tipo_acid</th>\n",
       "      <th>dia_sem</th>\n",
       "      <th>hora</th>\n",
       "      <th>noite_dia</th>\n",
       "      <th>regiao</th>\n",
       "      <th>hora_int</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>total_vitimas</th>\n",
       "      <th>soma_veiculos</th>\n",
       "      <th>data_meteo</th>\n",
       "      <th>chuva</th>\n",
       "      <th>chovendo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669196</td>\n",
       "      <td>AV FARRAPOS</td>\n",
       "      <td>AV SAO PEDRO</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 02:20:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>669089</td>\n",
       "      <td>AV BENTO GONCALVES</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669206</td>\n",
       "      <td>R SANTA FLORA</td>\n",
       "      <td>AV DA CAVALHADA</td>\n",
       "      <td>COLISÃO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>SUL</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669195</td>\n",
       "      <td>R SAO FRANCISCO DE ASSIS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EVENTUAL</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>683303</td>\n",
       "      <td>AV SENADOR TARSO DUTRA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>23</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predial1  queda_arr       data  feridos  feridos_gr  fatais  auto  taxi  \\\n",
       "0      2500          0 2020-01-01        0           0       0     2     0   \n",
       "1       598          0 2020-01-01        1           0       0     0     1   \n",
       "2         0          0 2020-01-01        0           0       0     2     0   \n",
       "3       399          0 2020-01-01        0           0       0     1     0   \n",
       "4       400          0 2020-01-01        1           1       0     0     0   \n",
       "\n",
       "   lotacao  onibus_urb  onibus_met  onibus_int  caminhao  moto  carroca  \\\n",
       "0        0           0           0           0         0     0        0   \n",
       "1        0           0           0           0         0     1        0   \n",
       "2        0           0           0           0         0     0        0   \n",
       "3        0           0           0           0         0     0        0   \n",
       "4        0           0           0           0         0     1        0   \n",
       "\n",
       "   bicicleta  outro  cont_vit  ups  patinete  idacidente  \\\n",
       "0          0      0         0    1         0      669196   \n",
       "1          0      0         1    5         0      669089   \n",
       "2          0      0         0    1         0      669206   \n",
       "3          0      0         0    1         0      669195   \n",
       "4          1      0         1    5         0      683303   \n",
       "\n",
       "                       log1             log2     tipo_acid dia_sem  \\\n",
       "0               AV FARRAPOS     AV SAO PEDRO  ABALROAMENTO  Quarta   \n",
       "1        AV BENTO GONCALVES             <NA>  ABALROAMENTO  Quarta   \n",
       "2             R SANTA FLORA  AV DA CAVALHADA       COLISÃO  Quarta   \n",
       "3  R SAO FRANCISCO DE ASSIS             <NA>      EVENTUAL  Quarta   \n",
       "4   AV SENADOR TARSO DUTRA              <NA>  ABALROAMENTO  Quarta   \n",
       "\n",
       "             hora noite_dia regiao  hora_int           data_hora  \\\n",
       "0 0 days 02:20:00     NOITE  NORTE         2 2020-01-01 02:20:00   \n",
       "1 0 days 03:00:00     NOITE  LESTE         3 2020-01-01 03:00:00   \n",
       "2 0 days 17:15:00       DIA    SUL        17 2020-01-01 17:15:00   \n",
       "3 0 days 17:15:00       DIA  NORTE        17 2020-01-01 17:15:00   \n",
       "4 0 days 23:00:00     NOITE  LESTE        23 2020-01-01 23:00:00   \n",
       "\n",
       "   total_vitimas  soma_veiculos          data_meteo  chuva  chovendo  \n",
       "0              0              2 2020-01-01 02:00:00   0.00         0  \n",
       "1              1              2 2020-01-01 03:00:00   0.00         0  \n",
       "2              0              2 2020-01-01 17:00:00   0.40         1  \n",
       "3              0              1 2020-01-01 17:00:00   5.70         1  \n",
       "4              1              2 2020-01-01 23:00:00   0.00         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from config import (\n",
    "    pd, sns, plt, np,\n",
    "    resumo_df, ajustar_tipos, \n",
    "    PATH_CLEAN, COLS_VEICULOS\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_parquet(PATH_CLEAN + \"df_limpo_chuva.parquet\")\n",
    "resumo_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a256c7d",
   "metadata": {},
   "source": [
    "### 2. Valida colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fec844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir formato de data\n",
    "df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\")\n",
    "\n",
    "# Derivar colunas úteis\n",
    "df[\"ano\"] = df[\"data\"].dt.year\n",
    "df[\"mes\"] = df[\"data\"].dt.month\n",
    "df[\"ano_mes\"] = df[\"data\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# Alvo deve ser não-negativo\n",
    "assert (df[\"ups\"] >= 0).all(), \"ups contém valores negativos; verifique o pré-processamento.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fe1ad",
   "metadata": {},
   "source": [
    "### 3) Seleciona features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fabd3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selecionadas: ['dia_sem', 'hora_int', 'noite_dia', 'regiao', 'log1', 'chuva', 'chovendo', 'auto', 'taxi', 'lotacao', 'onibus_urb', 'onibus_met', 'onibus_int', 'caminhao', 'moto', 'carroca', 'bicicleta', 'outro', 'patinete']\n"
     ]
    }
   ],
   "source": [
    "# aplicar tipagem padrão\n",
    "df = ajustar_tipos(df)\n",
    "\n",
    "# seleção de features\n",
    "cols_temporais = [\"dia_sem\", \"hora_int\", \"noite_dia\"]\n",
    "cols_geo      = [\"regiao\", \"log1\"]\n",
    "cols_clima    = [\"chuva\", \"chovendo\"]\n",
    "\n",
    "features = cols_temporais + cols_geo + cols_clima + COLS_VEICULOS\n",
    "target   = \"ups\"\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].astype(float).copy()\n",
    "\n",
    "print(\"Features selecionadas:\", features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c2060",
   "metadata": {},
   "source": [
    "4) Split temporal: treino/validação/teste\n",
    "* Treino: 2020–2023  \n",
    "* Validação: 2024   \n",
    "* Teste: 2025 (jan–mai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b99797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train (50718, 19) val (14836, 19) test (3283, 19)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar 2025 até maio (se houver 2025)\n",
    "df_treino = df[(df[\"ano\"] >= 2020) & (df[\"ano\"] <= 2023)]\n",
    "df_val    = df[df[\"ano\"] == 2024]\n",
    "df_teste  = df[df[\"ano\"] == 2025]\n",
    "if not df_teste.empty:\n",
    "    df_teste = df_teste[df_teste[\"mes\"] <= 5]\n",
    "\n",
    "def xy(dfx):\n",
    "    X = dfx[features].copy()\n",
    "    y = dfx[target].astype(float).copy()\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = xy(df_treino)\n",
    "X_val,   y_val   = xy(df_val)\n",
    "X_test,  y_test  = xy(df_teste)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"train\", X_train.shape,\n",
    "      \"val\",   X_val.shape,\n",
    "      \"test\",  X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e582bb",
   "metadata": {},
   "source": [
    "5) Pré-processamento (numérico + categórico) e modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f55b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferir tipos\n",
    "cat_cols = X_train.select_dtypes(include=[\"category\",\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "# Pipelines\n",
    "numeric = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler(with_mean=False))  # with_mean False para segurança em esparsidade\n",
    "])\n",
    "\n",
    "categorical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\",     OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric, num_cols),\n",
    "        (\"cat\", categorical, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "modelos = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"PoissonRegressor\": PoissonRegressor(alpha=1.0, max_iter=1000),  # requer y>=0 (ok p/ UPS)\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1),\n",
    "    \"HistGBR\": HistGradientBoostingRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbb4de",
   "metadata": {},
   "source": [
    "6) Treino, avaliação e seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f2b5de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'AV FARRAPOS'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nome, base_model \u001b[38;5;129;01min\u001b[39;00m modelos.items():\n\u001b[32m     10\u001b[39m     pipe = Pipeline(steps=[(\u001b[33m\"\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m\"\u001b[39m, preprocessor), (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, base_model)])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     yhat_val = pipe.predict(X_val)\n\u001b[32m     14\u001b[39m     met = avaliar(y_val, yhat_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:996\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    994\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:897\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    885\u001b[39m             extra_args = {}\n\u001b[32m    886\u001b[39m         jobs.append(\n\u001b[32m    887\u001b[39m             delayed(func)(\n\u001b[32m    888\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m             )\n\u001b[32m    895\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:719\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m    682\u001b[39m \u001b[33;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m \u001b[33;03m    Transformed samples.\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    718\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m last_step = \u001b[38;5;28mself\u001b[39m._final_estimator\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:897\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:452\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    436\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m    438\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/acidentes-poa/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:377\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[32m    372\u001b[39m     new_ve = \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    373\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    374\u001b[39m             \u001b[38;5;28mself\u001b[39m.strategy, ve\n\u001b[32m    375\u001b[39m         )\n\u001b[32m    376\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[31mValueError\u001b[39m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'AV FARRAPOS'"
     ]
    }
   ],
   "source": [
    "def avaliar(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nome, base_model in modelos.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", base_model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    yhat_val = pipe.predict(X_val)\n",
    "    met = avaliar(y_val, yhat_val)\n",
    "    resultados[nome] = {\"pipeline\": pipe, \"val\": met}\n",
    "\n",
    "# Ranking\n",
    "ranking = (pd.DataFrame({k: v[\"val\"] for k,v in resultados.items()})\n",
    "             .T.sort_values(by=[\"RMSE\",\"MAE\",\"R2\"], ascending=[True, True, False]))\n",
    "ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa720ac5",
   "metadata": {},
   "source": [
    "Escolher menor RMSE ou MAE e maior r² na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b605e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_nome = ranking.index[0]\n",
    "best_pipe = resultados[melhor_nome][\"pipeline\"]\n",
    "print(\"🏆 Melhor modelo (val):\", melhor_nome, resultados[melhor_nome][\"val\"])\n",
    "\n",
    "# Avaliar no teste (se existir)\n",
    "if not X_test.empty:\n",
    "    yhat_test = best_pipe.predict(X_test)\n",
    "    print(\"Teste:\", avaliar(y_test, yhat_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c83c1f",
   "metadata": {},
   "source": [
    "7) Importância de features & interpretabilidade\n",
    "\n",
    "Para árvores, usamos feature_importances_. Para modelos lineares, coeficientes.\n",
    "Se você tiver SHAP instalado, incluí um bloco opcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be243560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomes_features_transformados(preprocessor):\n",
    "    # Recupera nomes após OneHotEncoder\n",
    "    out = []\n",
    "    # num\n",
    "    out += num_cols\n",
    "    # cat\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "    cat_feat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    out += cat_feat_names\n",
    "    return out\n",
    "\n",
    "# Importância (quando aplicável)\n",
    "try:\n",
    "    model = best_pipe.named_steps[\"model\"]\n",
    "    feat_names = nomes_features_transformados(best_pipe.named_steps[\"prep\"])\n",
    "\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = pd.Series(model.feature_importances_, index=feat_names).sort_values(ascending=False).head(20)\n",
    "        ax = imp[::-1].plot(kind=\"barh\")\n",
    "        ax.set_title(f\"Top 20 importâncias — {melhor_nome}\")\n",
    "        plt.show()\n",
    "\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        coefs = pd.Series(model.coef_.ravel(), index=feat_names).sort_values()\n",
    "        ax = coefs.head(10).plot(kind=\"barh\"); plt.title(f\"Coef. (neg) — {melhor_nome}\"); plt.show()\n",
    "        ax = coefs.tail(10).plot(kind=\"barh\"); plt.title(f\"Coef. (pos) — {melhor_nome}\"); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Importância/coeficientes não disponíveis:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20852a",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) é uma ferramenta poderosa para interpretar modelos de machine learning, especialmente modelos complexos como árvores de decisão e redes neurais. Ele atribui a cada feature uma contribuição para a previsão do modelo, permitindo entender como cada variável influencia o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP and hasattr(best_pipe.named_steps[\"model\"], \"predict\"):\n",
    "    # Amostra para reduzir custo\n",
    "    amostra = X_val.sample(min(3000, len(X_val)), random_state=42)\n",
    "    X_val_trans = best_pipe.named_steps[\"prep\"].transform(amostra)\n",
    "\n",
    "    # Escolha do explainer depende do modelo\n",
    "    try:\n",
    "        explainer = shap.Explainer(best_pipe.named_steps[\"model\"])\n",
    "        shap_values = explainer(X_val_trans)\n",
    "        shap.plots.beeswarm(shap_values, max_display=20)\n",
    "    except Exception as e:\n",
    "        print(\"SHAP não pôde rodar com este modelo:\", e)\n",
    "else:\n",
    "    print(\"SHAP indisponível (biblioteca ausente) — pulando.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cadd02",
   "metadata": {},
   "source": [
    "8) Previsão temporal (mensal) com SARIMAX (opcional)\n",
    "\n",
    "Previsão do total mensal de UPS para avaliar tendência de severidade.\n",
    "Ajuste simples; melhore com covariáveis exógenas (chuva média mensal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_STATSMODELS:\n",
    "    # Série mensal de UPS\n",
    "    s_mensal = (df\n",
    "                .dropna(subset=[\"data\"])\n",
    "                .set_index(\"data\")\n",
    "                .resample(\"M\")[\"ups\"].sum())\n",
    "\n",
    "    # Treino até 2023, valida 2024, teste 2025-05\n",
    "    s_train = s_mensal.loc[: \"2023-12-31\"]\n",
    "    s_val   = s_mensal.loc[\"2024-01-01\":\"2024-12-31\"]\n",
    "    s_test  = s_mensal.loc[\"2025-01-01\":\"2025-05-31\"]\n",
    "\n",
    "    # Exógenas (chuva média mensal), se existir\n",
    "    if \"chuva\" in df.columns:\n",
    "        exo = df.set_index(\"data\").resample(\"M\")[\"chuva\"].mean()\n",
    "        exo_train = exo.loc[s_train.index]\n",
    "        exo_val   = exo.loc[s_val.index]\n",
    "        exo_test  = exo.loc[s_test.index] if not s_test.empty else None\n",
    "    else:\n",
    "        exo_train = exo_val = exo_test = None\n",
    "\n",
    "    # Modelo SARIMAX simples\n",
    "    mod = sm.tsa.statespace.SARIMAX(\n",
    "        s_train, order=(1,1,1), seasonal_order=(1,1,1,12),\n",
    "        exog=exo_train, enforce_stationarity=False, enforce_invertibility=False\n",
    "    )\n",
    "    res = mod.fit(disp=False)\n",
    "\n",
    "    pred_val = res.get_forecast(steps=len(s_val), exog=exo_val)\n",
    "    pred_mean_val = pred_val.predicted_mean\n",
    "    ci_val = pred_val.conf_int()\n",
    "\n",
    "    ax = s_mensal.plot(label=\"observado\", alpha=0.6)\n",
    "    pred_mean_val.plot(ax=ax, label=\"previsto (val)\")\n",
    "    ax.fill_between(ci_val.index, ci_val.iloc[:,0], ci_val.iloc[:,1], alpha=0.2)\n",
    "    ax.axvspan(pd.Timestamp(\"2024-01-01\"), pd.Timestamp(\"2024-12-31\"), color=\"orange\", alpha=0.1, label=\"val\")\n",
    "    if not s_test.empty:\n",
    "        ax.axvspan(pd.Timestamp(\"2025-01-01\"), pd.Timestamp(\"2025-05-31\"), color=\"green\", alpha=0.1, label=\"teste\")\n",
    "    ax.set_title(\"UPS mensal — observado vs previsão (SARIMAX)\")\n",
    "    ax.legend(); plt.show()\n",
    "\n",
    "    # Erros em validação\n",
    "    from math import sqrt\n",
    "    rmse_val = sqrt(((s_val - pred_mean_val)**2).mean())\n",
    "    mae_val = (s_val - pred_mean_val).abs().mean()\n",
    "    print({\"RMSE_val_mensal\": rmse_val, \"MAE_val_mensal\": mae_val})\n",
    "else:\n",
    "    print(\"statsmodels indisponível — pulando SARIMAX.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3acadd",
   "metadata": {},
   "source": [
    "9) Conclusões e próximos passos (guia)\n",
    "\n",
    "Desempenho: compare MAE/RMSE/R² entre os modelos; escolha o melhor (geralmente HistGBR e RF vão bem).\n",
    "\n",
    "Interpretabilidade: use importâncias e (se possível) SHAP para entender sinais/efeitos.\n",
    "\n",
    "Aprimoramentos:\n",
    "\n",
    "Features: harmônicos de hora (seno/cosseno), sazonalidade (mês), feriados, interação chuva×noite_dia.\n",
    "\n",
    "Espaço: agrupar log1 para reduzir cardinalidade (top-k + “outros”).\n",
    "\n",
    "Validação: CV em blocos temporais (TimeSeriesSplit) além do hold-out por ano.\n",
    "\n",
    "Incerteza: intervalos por quantile regression (HistGBR loss=\"quantile\") para cenários pessimista/otimista.\n",
    "\n",
    "Temporais: enriquecer SARIMAX com exógenas (chuva, feriados, mobilidade) e comparar com Prophet ou AutoARIMA (pmdarima)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942a8b8",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4712548",
   "metadata": {},
   "source": [
    "## 2. Definição do Target e Features\n",
    "\n",
    "- Target: `ups` (Índice de Severidade Ponderado — DENATRAN, 1987).\n",
    "- Features: condições climáticas, temporais, geográficas e veículos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"ups\"\n",
    "\n",
    "# Exemplo de seleção inicial de features\n",
    "cols_temporais = [\"ano\", \"mes\", \"dia_semana\", \"turno\"]\n",
    "cols_geo = [\"regiao\", \"log1\"]\n",
    "cols_clima = [\"precipitacao\", \"chuva_dia\"]\n",
    "from config import cols_veiculos  # já definido no config\n",
    "\n",
    "features = cols_temporais + cols_geo + cols_clima + cols_veiculos\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f701333",
   "metadata": {},
   "source": [
    "### 3. Separa treino, validação e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d2e1a",
   "metadata": {},
   "source": [
    "## 3. Divisão Treino / Validação / Teste\n",
    "\n",
    "- Treino: 2020–2023  \n",
    "- Validação: 2024  \n",
    "- Teste: jan–mai/2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ano\"] = df[\"ano\"].astype(int)\n",
    "\n",
    "df_train = df[df[\"ano\"] <= 2023]\n",
    "df_val = df[df[\"ano\"] == 2024]\n",
    "df_test = df[df[\"ano\"] == 2025]\n",
    "\n",
    "X_train, y_train = df_train[features], df_train[target]\n",
    "X_val, y_val = df_val[features], df_val[target]\n",
    "X_test, y_test = df_test[features], df_test[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b2b7b",
   "metadata": {},
   "source": [
    "### 4. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164ac90",
   "metadata": {},
   "source": [
    "## 4. Pré-Processamento\n",
    "\n",
    "- Codificação de variáveis categóricas\n",
    "- Escalonamento de variáveis numéricas\n",
    "- Balanceamento do target com SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d5483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_features = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21e5a4",
   "metadata": {},
   "source": [
    "### 5. Modelos Candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb6982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9580f",
   "metadata": {},
   "source": [
    "### 6. Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"model\", model)])\n",
    "    X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "    pipe.fit(X_res, y_res)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    y_proba = pipe.predict_proba(X_val)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
    "    \n",
    "    results[name] = {\n",
    "        \"classification_report\": classification_report(y_val, y_pred, output_dict=True),\n",
    "        \"roc_auc\": roc_auc_score(y_val, y_proba) if y_proba is not None else None\n",
    "    }\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b13c3c",
   "metadata": {},
   "source": [
    "### 7. Interpretação e Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ced24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Exemplo com RandomForest\n",
    "best_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", best_model)])\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "pipe.fit(X_res, y_res)\n",
    "\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "X_val_trans = preprocessor.transform(X_val)\n",
    "shap_values = explainer.shap_values(X_val_trans)\n",
    "shap.summary_plot(shap_values, X_val_trans, feature_names=preprocessor.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8e403",
   "metadata": {},
   "source": [
    "### 8. Modelagem Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Série mensal\n",
    "df_mensal = df.groupby([\"ano_mes\"])[\"ups\"].sum()\n",
    "train = df_mensal[:'2023-12']\n",
    "val = df_mensal['2024']\n",
    "test = df_mensal['2025-05']\n",
    "\n",
    "# SARIMAX (exemplo simples)\n",
    "model = sm.tsa.statespace.SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "sarimax_res = model.fit(disp=False)\n",
    "forecast = sarimax_res.get_forecast(steps=len(val))\n",
    "forecast_ci = forecast.conf_int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c56901",
   "metadata": {},
   "source": [
    "### 9. Discussão e Limitações\n",
    "\n",
    "- Comparar interpretabilidade (Regressão) vs performance (Ensembles).\n",
    "- Destacar importância de incerteza (Bao et al., 2020).\n",
    "- Ressaltar que modelos preditivos não garantem causalidade (Pearl et al., 2016).\n",
    "- Indicar próximos passos: ensembles híbridos, variáveis externas de mobilidade urbana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218fa7e9",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a692be",
   "metadata": {},
   "source": [
    "03. Pré processamento\n",
    "* seleção de features\n",
    "* balanceamento (SMOTE, undersampling)\n",
    "* normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39c7d8",
   "metadata": {},
   "source": [
    "4. Modelos candidatos\n",
    "* Classificação: Regressão Logística, Random Forest, XGBoost\n",
    "* Series Temporais: SARIMA, Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64acc2",
   "metadata": {},
   "source": [
    "5. Treinamento e validação\n",
    "* Separação treino/teste\n",
    "* Treinar modelos, guardar métricas (accuracy, recall, AUC)\n",
    "* Comparar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be28d95b",
   "metadata": {},
   "source": [
    "6. Interpretação\n",
    "* Importância das variáveis (ex.: feature_importances_ da Random Forest)\n",
    "* Gráficos de desempenho (ROC, matriz de confusão)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaac0b",
   "metadata": {},
   "source": [
    "7. Previsão para 2025\n",
    "* Usar o modelo escolhido para prever\n",
    "* Comparar com dados reais de 2025 quando disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f561ae8",
   "metadata": {},
   "source": [
    "## Referenciais Teóricos\n",
    "\n",
    "- Breiman (2001): *Two Cultures* → interpretação vs predição.\n",
    "- Bishop (2006), Hastie, Tibshirani & Friedman (2009), Murphy (2012): fundamentos estatísticos e probabilísticos.\n",
    "- Géron (2023), Müller & Guido (2016), Faceli et al. (2021): boas práticas em pipelines e scikit-learn.\n",
    "- Zabala (2019, 2021): aplicações de modelagem preditiva.\n",
    "- Pearl et al. (2016): inferência causal.\n",
    "- Vilone & Longo (2020): interpretabilidade.\n",
    "- Bao et al. (2020): incerteza espaço-temporal.\n",
    "- Chen et al. (2025): ensembles avançados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
