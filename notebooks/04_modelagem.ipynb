{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2caf0e6",
   "metadata": {},
   "source": [
    "# 04 - Modelagem Preditiva\n",
    "Autora: Fernanda Baptista de Siqueira  \n",
    "Curso: MBA em Tecnologia para Negócios – AI, Data Science e Big Data  \n",
    "Tema: Análise de Acidentes de Trânsito em Porto Alegre (2020–2024)  \n",
    "Origem DataFrame: Equipe Armazém de Dados de Mobilidade - EAMOB/CIET  \n",
    "https://dadosabertos.poa.br/dataset/acidentes-de-transito-acidentes (11/05/2025)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3a2b2",
   "metadata": {},
   "source": [
    "### 1. Importa bibliotecas e funções. Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cd15eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (68837, 35)\n",
      "\n",
      "Tipos de dados:\n",
      "predial1                   Int32\n",
      "queda_arr                  Int32\n",
      "data              datetime64[ns]\n",
      "feridos                    Int32\n",
      "feridos_gr                 Int32\n",
      "fatais                     Int32\n",
      "auto                       Int32\n",
      "taxi                       Int32\n",
      "lotacao                    Int32\n",
      "onibus_urb                 Int32\n",
      "onibus_met                 Int32\n",
      "onibus_int                 Int32\n",
      "caminhao                   Int32\n",
      "moto                       Int32\n",
      "carroca                    Int32\n",
      "bicicleta                  Int32\n",
      "outro                      Int32\n",
      "cont_vit                   Int32\n",
      "ups                        Int32\n",
      "patinete                   Int32\n",
      "idacidente                 Int32\n",
      "log1              string[python]\n",
      "log2              string[python]\n",
      "tipo_acid               category\n",
      "dia_sem                 category\n",
      "hora             timedelta64[ns]\n",
      "noite_dia               category\n",
      "regiao                  category\n",
      "hora_int                   int64\n",
      "data_hora         datetime64[ns]\n",
      "total_vitimas              Int32\n",
      "soma_veiculos              Int32\n",
      "data_meteo        datetime64[ns]\n",
      "chuva                    float32\n",
      "chovendo                   int64\n",
      "dtype: object\n",
      "\n",
      "Nulos por coluna:\n",
      "predial1          4038\n",
      "queda_arr            0\n",
      "data                 0\n",
      "feridos              0\n",
      "feridos_gr           0\n",
      "fatais               0\n",
      "auto                 0\n",
      "taxi                 0\n",
      "lotacao              0\n",
      "onibus_urb           0\n",
      "onibus_met           0\n",
      "onibus_int           0\n",
      "caminhao             0\n",
      "moto                 0\n",
      "carroca              0\n",
      "bicicleta            0\n",
      "outro                0\n",
      "cont_vit             0\n",
      "ups                  0\n",
      "patinete             0\n",
      "idacidente           0\n",
      "log1                 0\n",
      "log2             49862\n",
      "tipo_acid            0\n",
      "dia_sem              0\n",
      "hora                 0\n",
      "noite_dia            0\n",
      "regiao               0\n",
      "hora_int             0\n",
      "data_hora            0\n",
      "total_vitimas        0\n",
      "soma_veiculos        0\n",
      "data_meteo           0\n",
      "chuva                0\n",
      "chovendo             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predial1</th>\n",
       "      <th>queda_arr</th>\n",
       "      <th>data</th>\n",
       "      <th>feridos</th>\n",
       "      <th>feridos_gr</th>\n",
       "      <th>fatais</th>\n",
       "      <th>auto</th>\n",
       "      <th>taxi</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>onibus_urb</th>\n",
       "      <th>onibus_met</th>\n",
       "      <th>onibus_int</th>\n",
       "      <th>caminhao</th>\n",
       "      <th>moto</th>\n",
       "      <th>carroca</th>\n",
       "      <th>bicicleta</th>\n",
       "      <th>outro</th>\n",
       "      <th>cont_vit</th>\n",
       "      <th>ups</th>\n",
       "      <th>patinete</th>\n",
       "      <th>idacidente</th>\n",
       "      <th>log1</th>\n",
       "      <th>log2</th>\n",
       "      <th>tipo_acid</th>\n",
       "      <th>dia_sem</th>\n",
       "      <th>hora</th>\n",
       "      <th>noite_dia</th>\n",
       "      <th>regiao</th>\n",
       "      <th>hora_int</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>total_vitimas</th>\n",
       "      <th>soma_veiculos</th>\n",
       "      <th>data_meteo</th>\n",
       "      <th>chuva</th>\n",
       "      <th>chovendo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669196</td>\n",
       "      <td>AV FARRAPOS</td>\n",
       "      <td>AV SAO PEDRO</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 02:20:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>669089</td>\n",
       "      <td>AV BENTO GONCALVES</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669206</td>\n",
       "      <td>R SANTA FLORA</td>\n",
       "      <td>AV DA CAVALHADA</td>\n",
       "      <td>COLISÃO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>SUL</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669195</td>\n",
       "      <td>R SAO FRANCISCO DE ASSIS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EVENTUAL</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 17:15:00</td>\n",
       "      <td>DIA</td>\n",
       "      <td>NORTE</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-01 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>683303</td>\n",
       "      <td>AV SENADOR TARSO DUTRA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ABALROAMENTO</td>\n",
       "      <td>Quarta</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>NOITE</td>\n",
       "      <td>LESTE</td>\n",
       "      <td>23</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predial1  queda_arr       data  feridos  feridos_gr  fatais  auto  taxi  \\\n",
       "0      2500          0 2020-01-01        0           0       0     2     0   \n",
       "1       598          0 2020-01-01        1           0       0     0     1   \n",
       "2         0          0 2020-01-01        0           0       0     2     0   \n",
       "3       399          0 2020-01-01        0           0       0     1     0   \n",
       "4       400          0 2020-01-01        1           1       0     0     0   \n",
       "\n",
       "   lotacao  onibus_urb  onibus_met  onibus_int  caminhao  moto  carroca  \\\n",
       "0        0           0           0           0         0     0        0   \n",
       "1        0           0           0           0         0     1        0   \n",
       "2        0           0           0           0         0     0        0   \n",
       "3        0           0           0           0         0     0        0   \n",
       "4        0           0           0           0         0     1        0   \n",
       "\n",
       "   bicicleta  outro  cont_vit  ups  patinete  idacidente  \\\n",
       "0          0      0         0    1         0      669196   \n",
       "1          0      0         1    5         0      669089   \n",
       "2          0      0         0    1         0      669206   \n",
       "3          0      0         0    1         0      669195   \n",
       "4          1      0         1    5         0      683303   \n",
       "\n",
       "                       log1             log2     tipo_acid dia_sem  \\\n",
       "0               AV FARRAPOS     AV SAO PEDRO  ABALROAMENTO  Quarta   \n",
       "1        AV BENTO GONCALVES             <NA>  ABALROAMENTO  Quarta   \n",
       "2             R SANTA FLORA  AV DA CAVALHADA       COLISÃO  Quarta   \n",
       "3  R SAO FRANCISCO DE ASSIS             <NA>      EVENTUAL  Quarta   \n",
       "4   AV SENADOR TARSO DUTRA              <NA>  ABALROAMENTO  Quarta   \n",
       "\n",
       "             hora noite_dia regiao  hora_int           data_hora  \\\n",
       "0 0 days 02:20:00     NOITE  NORTE         2 2020-01-01 02:20:00   \n",
       "1 0 days 03:00:00     NOITE  LESTE         3 2020-01-01 03:00:00   \n",
       "2 0 days 17:15:00       DIA    SUL        17 2020-01-01 17:15:00   \n",
       "3 0 days 17:15:00       DIA  NORTE        17 2020-01-01 17:15:00   \n",
       "4 0 days 23:00:00     NOITE  LESTE        23 2020-01-01 23:00:00   \n",
       "\n",
       "   total_vitimas  soma_veiculos          data_meteo  chuva  chovendo  \n",
       "0              0              2 2020-01-01 02:00:00   0.00         0  \n",
       "1              1              2 2020-01-01 03:00:00   0.00         0  \n",
       "2              0              2 2020-01-01 17:00:00   0.40         1  \n",
       "3              0              1 2020-01-01 17:00:00   5.70         1  \n",
       "4              1              2 2020-01-01 23:00:00   0.00         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from config import (\n",
    "    pd, sns, plt, np,\n",
    "    resumo_df, ajustar_tipos, \n",
    "    PATH_CLEAN, COLS_VEICULOS,\n",
    "    COLS_CAT, COLS_INT, COLS_STR\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_parquet(PATH_CLEAN + \"df_limpo_chuva.parquet\")\n",
    "resumo_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a256c7d",
   "metadata": {},
   "source": [
    "### 2. Valida colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fec844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir formato de data\n",
    "df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\")\n",
    "\n",
    "# Derivar colunas úteis\n",
    "df[\"ano\"] = df[\"data\"].dt.year\n",
    "df[\"mes\"] = df[\"data\"].dt.month\n",
    "df[\"ano_mes\"] = df[\"data\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# Alvo deve ser não-negativo\n",
    "assert (df[\"ups\"] >= 0).all(), \"ups contém valores negativos; verifique o pré-processamento.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fe1ad",
   "metadata": {},
   "source": [
    "### 3. Seleciona features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fabd3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selecionadas: ['dia_sem', 'hora_int', 'noite_dia', 'regiao', 'log1', 'chuva', 'chovendo', 'auto', 'bicicleta', 'lotacao', 'onibus_urb', 'onibus_met', 'onibus_int', 'caminhao', 'moto', 'carroca', 'taxi', 'outro', 'patinete']\n"
     ]
    }
   ],
   "source": [
    "# aplicar tipagem padrão\n",
    "df = ajustar_tipos(df)\n",
    "\n",
    "# seleção de features\n",
    "cols_temporais = [\"dia_sem\", \"hora_int\", \"noite_dia\"]\n",
    "cols_geo      = [\"regiao\", \"log1\"]\n",
    "cols_clima    = [\"chuva\", \"chovendo\"]\n",
    "\n",
    "features = cols_temporais + cols_geo + cols_clima + COLS_VEICULOS\n",
    "target   = \"ups\"\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].astype(float).copy()\n",
    "\n",
    "print(\"Features selecionadas:\", features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c2060",
   "metadata": {},
   "source": [
    "### 4. Split temporal: treino/validação/teste\n",
    "* Treino: 2020–2023  \n",
    "* Validação: 2024   \n",
    "* Teste: 2025 (jan–mai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b99797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train (50718, 19) val (14836, 19) test (3283, 19)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar 2025 até maio (se houver 2025)\n",
    "df_treino = df[(df[\"ano\"] >= 2020) & (df[\"ano\"] <= 2023)]\n",
    "df_val    = df[df[\"ano\"] == 2024]\n",
    "df_teste  = df[df[\"ano\"] == 2025]\n",
    "if not df_teste.empty:\n",
    "    df_teste = df_teste[df_teste[\"mes\"] <= 5]\n",
    "\n",
    "def xy(dfx):\n",
    "    X = dfx[features].copy()\n",
    "    y = dfx[target].astype(float).copy()\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = xy(df_treino)\n",
    "X_val,   y_val   = xy(df_val)\n",
    "X_test,  y_test  = xy(df_teste)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"train\", X_train.shape,\n",
    "      \"val\",   X_val.shape,\n",
    "      \"test\",  X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e582bb",
   "metadata": {},
   "source": [
    "### 5. Pré-processamento (numérico + categórico) e modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f55b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in COLS_INT if c in X_train.columns]\n",
    "cat_cols = [c for c in (COLS_CAT + COLS_STR) if c in X_train.columns]\n",
    "\n",
    "# Pipelines para cada tipo de dado\n",
    "numeric = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler(with_mean=False))  # segurança para saída esparsa\n",
    "])\n",
    "\n",
    "categorical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\",     OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# ColumnTransformer unindo os dois blocos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric, num_cols),\n",
    "        (\"cat\", categorical, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Modelos candidatos\n",
    "modelos = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"PoissonRegressor\": PoissonRegressor(alpha=1.0, max_iter=1000),  # requer y>=0 (ok para UPS)\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=300, max_depth=None, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"HistGBR\": HistGradientBoostingRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbb4de",
   "metadata": {},
   "source": [
    "6) Treino, avaliação e seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f2b5de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m pipe.fit(X_train, y_train)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Avalia no conjunto de validação\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m score = pipe.score(\u001b[43mX_valid\u001b[49m, y_valid)\n\u001b[32m     16\u001b[39m resultados[nome] = score\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnome\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "# Dicionário para armazenar resultados\n",
    "resultados = {}\n",
    "\n",
    "for nome, base_model in modelos.items():\n",
    "    # Cria pipeline com pré-processamento + modelo\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", base_model)\n",
    "    ])\n",
    "    \n",
    "    # Treina\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Avalia no conjunto de validação\n",
    "    score = pipe.score(X_valid, y_valid)\n",
    "    resultados[nome] = score\n",
    "    \n",
    "    print(f\"{nome}: {score:.4f}\")\n",
    "\n",
    "# Ordena por performance (maior primeiro)\n",
    "ranking = sorted(resultados.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nRanking dos modelos:\")\n",
    "for modelo, score in ranking:\n",
    "    print(f\"{modelo}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa720ac5",
   "metadata": {},
   "source": [
    "Escolher menor RMSE ou MAE e maior r² na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b605e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_nome = ranking.index[0]\n",
    "best_pipe = resultados[melhor_nome][\"pipeline\"]\n",
    "print(\"🏆 Melhor modelo (val):\", melhor_nome, resultados[melhor_nome][\"val\"])\n",
    "\n",
    "# Avaliar no teste (se existir)\n",
    "if not X_test.empty:\n",
    "    yhat_test = best_pipe.predict(X_test)\n",
    "    print(\"Teste:\", avaliar(y_test, yhat_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c83c1f",
   "metadata": {},
   "source": [
    "7) Importância de features & interpretabilidade\n",
    "\n",
    "Para árvores, usamos feature_importances_. Para modelos lineares, coeficientes.\n",
    "Se você tiver SHAP instalado, incluí um bloco opcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be243560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomes_features_transformados(preprocessor):\n",
    "    # Recupera nomes após OneHotEncoder\n",
    "    out = []\n",
    "    # num\n",
    "    out += num_cols\n",
    "    # cat\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "    cat_feat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    out += cat_feat_names\n",
    "    return out\n",
    "\n",
    "# Importância (quando aplicável)\n",
    "try:\n",
    "    model = best_pipe.named_steps[\"model\"]\n",
    "    feat_names = nomes_features_transformados(best_pipe.named_steps[\"prep\"])\n",
    "\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = pd.Series(model.feature_importances_, index=feat_names).sort_values(ascending=False).head(20)\n",
    "        ax = imp[::-1].plot(kind=\"barh\")\n",
    "        ax.set_title(f\"Top 20 importâncias — {melhor_nome}\")\n",
    "        plt.show()\n",
    "\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        coefs = pd.Series(model.coef_.ravel(), index=feat_names).sort_values()\n",
    "        ax = coefs.head(10).plot(kind=\"barh\"); plt.title(f\"Coef. (neg) — {melhor_nome}\"); plt.show()\n",
    "        ax = coefs.tail(10).plot(kind=\"barh\"); plt.title(f\"Coef. (pos) — {melhor_nome}\"); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Importância/coeficientes não disponíveis:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20852a",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) é uma ferramenta poderosa para interpretar modelos de machine learning, especialmente modelos complexos como árvores de decisão e redes neurais. Ele atribui a cada feature uma contribuição para a previsão do modelo, permitindo entender como cada variável influencia o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP and hasattr(best_pipe.named_steps[\"model\"], \"predict\"):\n",
    "    # Amostra para reduzir custo\n",
    "    amostra = X_val.sample(min(3000, len(X_val)), random_state=42)\n",
    "    X_val_trans = best_pipe.named_steps[\"prep\"].transform(amostra)\n",
    "\n",
    "    # Escolha do explainer depende do modelo\n",
    "    try:\n",
    "        explainer = shap.Explainer(best_pipe.named_steps[\"model\"])\n",
    "        shap_values = explainer(X_val_trans)\n",
    "        shap.plots.beeswarm(shap_values, max_display=20)\n",
    "    except Exception as e:\n",
    "        print(\"SHAP não pôde rodar com este modelo:\", e)\n",
    "else:\n",
    "    print(\"SHAP indisponível (biblioteca ausente) — pulando.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cadd02",
   "metadata": {},
   "source": [
    "8) Previsão temporal (mensal) com SARIMAX (opcional)\n",
    "\n",
    "Previsão do total mensal de UPS para avaliar tendência de severidade.\n",
    "Ajuste simples; melhore com covariáveis exógenas (chuva média mensal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_STATSMODELS:\n",
    "    # Série mensal de UPS\n",
    "    s_mensal = (df\n",
    "                .dropna(subset=[\"data\"])\n",
    "                .set_index(\"data\")\n",
    "                .resample(\"M\")[\"ups\"].sum())\n",
    "\n",
    "    # Treino até 2023, valida 2024, teste 2025-05\n",
    "    s_train = s_mensal.loc[: \"2023-12-31\"]\n",
    "    s_val   = s_mensal.loc[\"2024-01-01\":\"2024-12-31\"]\n",
    "    s_test  = s_mensal.loc[\"2025-01-01\":\"2025-05-31\"]\n",
    "\n",
    "    # Exógenas (chuva média mensal), se existir\n",
    "    if \"chuva\" in df.columns:\n",
    "        exo = df.set_index(\"data\").resample(\"M\")[\"chuva\"].mean()\n",
    "        exo_train = exo.loc[s_train.index]\n",
    "        exo_val   = exo.loc[s_val.index]\n",
    "        exo_test  = exo.loc[s_test.index] if not s_test.empty else None\n",
    "    else:\n",
    "        exo_train = exo_val = exo_test = None\n",
    "\n",
    "    # Modelo SARIMAX simples\n",
    "    mod = sm.tsa.statespace.SARIMAX(\n",
    "        s_train, order=(1,1,1), seasonal_order=(1,1,1,12),\n",
    "        exog=exo_train, enforce_stationarity=False, enforce_invertibility=False\n",
    "    )\n",
    "    res = mod.fit(disp=False)\n",
    "\n",
    "    pred_val = res.get_forecast(steps=len(s_val), exog=exo_val)\n",
    "    pred_mean_val = pred_val.predicted_mean\n",
    "    ci_val = pred_val.conf_int()\n",
    "\n",
    "    ax = s_mensal.plot(label=\"observado\", alpha=0.6)\n",
    "    pred_mean_val.plot(ax=ax, label=\"previsto (val)\")\n",
    "    ax.fill_between(ci_val.index, ci_val.iloc[:,0], ci_val.iloc[:,1], alpha=0.2)\n",
    "    ax.axvspan(pd.Timestamp(\"2024-01-01\"), pd.Timestamp(\"2024-12-31\"), color=\"orange\", alpha=0.1, label=\"val\")\n",
    "    if not s_test.empty:\n",
    "        ax.axvspan(pd.Timestamp(\"2025-01-01\"), pd.Timestamp(\"2025-05-31\"), color=\"green\", alpha=0.1, label=\"teste\")\n",
    "    ax.set_title(\"UPS mensal — observado vs previsão (SARIMAX)\")\n",
    "    ax.legend(); plt.show()\n",
    "\n",
    "    # Erros em validação\n",
    "    from math import sqrt\n",
    "    rmse_val = sqrt(((s_val - pred_mean_val)**2).mean())\n",
    "    mae_val = (s_val - pred_mean_val).abs().mean()\n",
    "    print({\"RMSE_val_mensal\": rmse_val, \"MAE_val_mensal\": mae_val})\n",
    "else:\n",
    "    print(\"statsmodels indisponível — pulando SARIMAX.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3acadd",
   "metadata": {},
   "source": [
    "9) Conclusões e próximos passos (guia)\n",
    "\n",
    "Desempenho: compare MAE/RMSE/R² entre os modelos; escolha o melhor (geralmente HistGBR e RF vão bem).\n",
    "\n",
    "Interpretabilidade: use importâncias e (se possível) SHAP para entender sinais/efeitos.\n",
    "\n",
    "Aprimoramentos:\n",
    "\n",
    "Features: harmônicos de hora (seno/cosseno), sazonalidade (mês), feriados, interação chuva×noite_dia.\n",
    "\n",
    "Espaço: agrupar log1 para reduzir cardinalidade (top-k + “outros”).\n",
    "\n",
    "Validação: CV em blocos temporais (TimeSeriesSplit) além do hold-out por ano.\n",
    "\n",
    "Incerteza: intervalos por quantile regression (HistGBR loss=\"quantile\") para cenários pessimista/otimista.\n",
    "\n",
    "Temporais: enriquecer SARIMAX com exógenas (chuva, feriados, mobilidade) e comparar com Prophet ou AutoARIMA (pmdarima)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942a8b8",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f561ae8",
   "metadata": {},
   "source": [
    "## Referenciais Teóricos\n",
    "\n",
    "- Breiman (2001): *Two Cultures* → interpretação vs predição.\n",
    "- Bishop (2006), Hastie, Tibshirani & Friedman (2009), Murphy (2012): fundamentos estatísticos e probabilísticos.\n",
    "- Géron (2023), Müller & Guido (2016), Faceli et al. (2021): boas práticas em pipelines e scikit-learn.\n",
    "- Zabala (2019, 2021): aplicações de modelagem preditiva.\n",
    "- Pearl et al. (2016): inferência causal.\n",
    "- Vilone & Longo (2020): interpretabilidade.\n",
    "- Bao et al. (2020): incerteza espaço-temporal.\n",
    "- Chen et al. (2025): ensembles avançados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
